# FastAPI Code Audit Report

**Date:** January 17, 2026  
**Status:** COMPREHENSIVE LINE-BY-LINE REVIEW  
**Severity Levels:** üî¥ CRITICAL | üü† HIGH | üü° MEDIUM | üü¢ LOW | ‚ÑπÔ∏è INFO

---

## Executive Summary

Your FastAPI application has **good foundations** with security utilities in place, but several code quality issues need attention:

- ‚úÖ **SQL Injection Protection:** Well-implemented with ParameterizedQueryBuilder
- ‚úÖ **Auth System:** JWT validation in place
- ‚ö†Ô∏è **Exception Handling:** Several bare excepts and overly broad exception catching
- ‚ö†Ô∏è **Resource Management:** Potential file handle and connection leaks
- ‚ö†Ô∏è **Error Messages:** Sensitive information leakage in some responses
- üü° **Async/Await:** Some non-async calls in async contexts
- üü° **Logging:** Inconsistent logging levels and missing context
- üü° **Input Validation:** Not consistently applied across all endpoints

---

## üî¥ CRITICAL ISSUES

### 1. **SDXL Image Generation - Missing ImageService Error Handling**

**File:** `src/cofounder_agent/routes/task_routes.py:2045-2090`  
**Severity:** üî¥ CRITICAL

**Issue:**

```python
# This catches ALL exceptions, including KeyboardInterrupt, SystemExit
except Exception as e:
    logger.error(f"SDXL image generation error: {e}", exc_info=True)
    raise HTTPException(...)
```

**Problems:**

- Generic `Exception` is too broad (catches system exceptions)
- `ImageService()` initialization could fail silently
- No validation that image_service.generate_image() is actually awaitable
- Path traversal vulnerability in `Path.home() / "Downloads" / ...` with user-controlled `task_id`

**Fix:**

```python
except (OSError, IOError, RuntimeError, ValueError) as e:
    # Specific exceptions only
    logger.error(f"SDXL image generation error: {type(e).__name__}: {e}", exc_info=True)
    raise HTTPException(...)
except asyncio.TimeoutError:
    logger.warning("SDXL generation timeout")
    raise HTTPException(status_code=408, detail="Image generation timeout")
except Exception as e:  # Only catch remaining exceptions
    logger.critical(f"Unexpected error in SDXL generation: {e}", exc_info=True)
    raise HTTPException(status_code=500, detail="Internal server error")
```

---

### 2. **Database Connection Pool - No Timeout or Reconnection**

**File:** `src/cofounder_agent/services/database_service.py:80-85`

**Issue:**

```python
self.pool = await asyncpg.create_pool(
    self.database_url,
    min_size=min_size,
    max_size=max_size,
    timeout=30,  # ‚ùå Only connection creation timeout, not query timeout
)
```

**Problems:**

- No `command_timeout` set (queries can hang indefinitely)
- No `max_cached_statement_lifetime` (statement cache can grow unbounded)
- No `max_queries_cached` limit
- Pool doesn't recover from connection failures automatically
- No healthcheck

**Fix:**

```python
self.pool = await asyncpg.create_pool(
    self.database_url,
    min_size=min_size,
    max_size=max_size,
    timeout=30,
    command_timeout=30,  # ‚úÖ Add query timeout
    max_cached_statement_lifetime=300,  # ‚úÖ Cache lifecycle
    max_queries_cached=100,  # ‚úÖ Limit statement cache
    connection_class=asyncpg.Connection,
    init=self._init_connection,  # ‚úÖ Custom connection setup
)
```

---

### 3. **Task Approval - Missing Atomic Transaction for Auto-Publish**

**File:** `src/cofounder_agent/routes/task_routes.py:1620-1720`

**Issue:**

```python
# Status updated to approved
await db_service.update_task_status(task_id, "approved", ...)

# If this fails, task is stuck in "approved" status
if approved and auto_publish:
    await db_service.update_task_status(task_id, "published", ...)
    # If this fails, post may not be created
    post = await db_service.create_post(...)
```

**Problems:**

- No transaction wrapping: if publish fails, task is left in inconsistent state
- Post creation happens AFTER status update
- No rollback mechanism
- Exception is caught but logged, masking failure

**Fix:**

```python
async with db_service.pool.acquire() as conn:
    async with conn.transaction():
        # Update to approved
        await conn.execute(...)

        if approved and auto_publish:
            # Create post FIRST (in transaction)
            post = await db_service.content.create_post_in_tx(conn, post_data)
            # THEN update status to published
            await conn.execute(...)
```

---

## üü† HIGH SEVERITY ISSUES

### 4. **Auth Token Validation - No Expiration Check**

**File:** `src/cofounder_agent/routes/auth_unified.py:200-210`

**Issue:**

```python
def get_current_user(request: Request) -> Dict[str, Any]:
    # ...
    claims = JWTTokenValidator.verify_token(token)  # ‚úÖ Good
    # But what if expired claim exists?
    user_id = claims.get("user_id")  # No exp check here
```

**Need to verify** `JWTTokenValidator.verify_token()` actually checks `exp` claim.

**Check this:**

```bash
# In token_validator.py, verify:
- `exp` claim is always checked
- Comparison uses current time with timezone awareness
- Handles missing `exp` claim (should be rejected)
```

---

### 5. **Pexels API - No Rate Limiting or Caching**

**File:** `src/cofounder_agent/routes/task_routes.py:2010-2025`

**Issue:**

```python
async with aiohttp.ClientSession() as session:
    async with session.get(
        "https://api.pexels.com/v1/search",
        # ‚ùå No X-RateLimit headers checked
        # ‚ùå Same search repeated = duplicate API calls
        # ‚ùå No backoff strategy
```

**Problems:**

- No cache for repeated image searches
- Pexels rate limit not respected (429 not handled)
- No exponential backoff
- Session created for every request (inefficient)

**Fix:**

```python
# Global cache (or Redis)
search_cache = {}

# Check cache first
cache_key = f"pexels_{search_query}"
if cache_key in search_cache:
    return search_cache[cache_key]

# Rate limit awareness
remaining = response.headers.get('X-RateLimit-Remaining')
if int(remaining) < 5:
    logger.warning("Pexels rate limit nearly exhausted")

# Cache result
search_cache[cache_key] = result
```

---

### 6. **Download Folder Path Traversal**

**File:** `src/cofounder_agent/routes/task_routes.py:2052`

**Issue:**

```python
task_id_str = task_id[:8] if task_id else "no-task"
output_file = f"sdxl_{timestamp}_{task_id_str}.png"  # ‚úÖ Good - truncated
output_path = os.path.join(downloads_path, output_file)
```

**Actually OK** but consider:

- Timestamp collision risk (same second = same filename overwrite)
- Should use UUID in filename

**Better:**

```python
import uuid
output_file = f"sdxl_{uuid.uuid4().hex[:8]}.png"  # ‚úÖ Guaranteed unique
```

---

## üü° MEDIUM SEVERITY ISSUES

### 7. **Bare Exception Catches in Image Generation**

**File:** `src/cofounder_agent/routes/task_routes.py:2040`

**Issue:**

```python
try:
    import os
    from pathlib import Path
    from services.image_service import ImageService
    # ...
except Exception as e:  # ‚ùå Too broad
```

**Should be:**

```python
try:
    # imports
except ImportError:
    logger.error("ImageService not available")
    raise HTTPException(status_code=501, detail="Image generation not available")
```

---

### 8. **Unused Imports**

**File:** `src/cofounder_agent/routes/task_routes.py:30-32`

```python
import json
import json  # ‚ùå DUPLICATE IMPORT!
import logging
```

---

### 9. **JSON Parsing Without Validation**

**File:** `src/cofounder_agent/routes/task_routes.py:1620`

**Issue:**

```python
task_result_data = updated_task.get("result", {})
if isinstance(task_result_data, str):
    task_result_data = json.loads(task_result_data) if task_result_data else {}
    # ‚ùå No try/except on json.loads()
```

**Fix:**

```python
if isinstance(task_result_data, str):
    try:
        task_result_data = json.loads(task_result_data)
    except json.JSONDecodeError:
        logger.warning(f"Invalid JSON in task result: {task_result_data[:100]}")
        task_result_data = {}
```

---

### 10. **Task Status Update - Validation Missing**

**File:** `src/cofounder_agent/routes/task_routes.py:1600-1615`

**Issue:**

```python
# Check if task is in a state that can be approved/rejected
current_status = task.get("status", "unknown")
allowed_statuses = ["awaiting_approval", "pending", "in_progress", "completed", "rejected"]
if current_status not in allowed_statuses:
    # ‚ùå Allows transition from ANY status to rejected
    # Should only allow specific transitions
```

**Better approach:**

```python
# Use TaskStatus enum for transitions
valid_transitions = {
    "awaiting_approval": ["approved", "rejected"],
    "pending": ["awaiting_approval"],
    "in_progress": ["completed", "failed"],
    # ...
}

new_status = "approved" if approved else "rejected"
if new_status not in valid_transitions.get(current_status, []):
    raise HTTPException(
        status_code=400,
        detail=f"Cannot transition from {current_status} to {new_status}"
    )
```

---

### 11. **Logging Without Context**

**File:** Multiple files

**Issue:**

```python
logger.info("Generating image with SDXL")  # ‚ùå No context
logger.error(f"Error: {e}")  # ‚ùå Generic
```

**Should be:**

```python
logger.info(f"[task_id={task_id}] Generating image with SDXL: {topic}")
logger.error(f"[task_id={task_id}] SDXL generation failed: {type(e).__name__}: {e}", exc_info=True)
```

---

### 12. **Response Model Mismatch**

**File:** `src/cofounder_agent/routes/task_routes.py:1970-1975`

**Issue:**

```python
@router.post(
    "/{task_id}/generate-image",
    response_model=dict,  # ‚ùå Should be Pydantic model
    # ...
)
```

**Fix:**

```python
from pydantic import BaseModel

class ImageGenerationResponse(BaseModel):
    image_url: str
    source: str
    message: str
    timestamp: datetime = Field(default_factory=datetime.now)

@router.post(
    "/{task_id}/generate-image",
    response_model=ImageGenerationResponse,  # ‚úÖ Typed
)
```

---

## üü¢ LOW SEVERITY ISSUES

### 13. **Missing Docstring Parameters**

**File:** `src/cofounder_agent/routes/task_routes.py:1975-2000`

The endpoint docstring should document:

- Response codes (200, 400, 404, 500, 501)
- Example curl command
- Rate limits (if any)

---

### 14. **Timezone Awareness**

**File:** Multiple files

Some datetime creations use naive datetime:

```python
datetime.now()  # ‚ùå Naive
```

Should be:

```python
datetime.now(timezone.utc)  # ‚úÖ Aware
```

---

### 15. **Type Hints Missing**

**File:** `src/cofounder_agent/routes/task_routes.py:2070`

```python
# Missing return type
success = await image_service.generate_image(...)  # What type is `success`?
```

Should be:

```python
success: bool = await image_service.generate_image(...)
```

---

## ‚úÖ GOOD PRACTICES FOUND

1. **‚úÖ Parameterized Queries** - SQL injection prevention is solid
2. **‚úÖ Async/Await Usage** - Most endpoints properly async
3. **‚úÖ Error Logging** - Generally good logging with exc_info=True
4. **‚úÖ JWT Token Validation** - Centralized in dependency
5. **‚úÖ Environment Variables** - Proper use of os.getenv()
6. **‚úÖ Connection Pooling** - asyncpg pool configured
7. **‚úÖ Status Code Consistency** - Proper HTTP status codes

---

## üìã ACTION ITEMS

| Priority | Issue                             | File                | Fix Time |
| -------- | --------------------------------- | ------------------- | -------- |
| üî¥ P0    | Transaction atomicity for publish | task_routes.py      | 2h       |
| üî¥ P0    | ImageService error handling       | task_routes.py      | 1h       |
| üü† P1    | Database timeout config           | database_service.py | 1h       |
| üü† P1    | Pexels rate limiting              | task_routes.py      | 2h       |
| üü° P2    | Duplicate import                  | task_routes.py      | 5m       |
| üü° P2    | JSON parse error handling         | task_routes.py      | 30m      |
| üü° P2    | Task state transitions            | task_routes.py      | 1h       |
| üü° P2    | Type hints                        | various             | 3h       |

---

## Summary Statistics

- **Total Issues Found:** 15
- **Critical:** 3
- **High:** 3
- **Medium:** 7
- **Low:** 2
- **Total Estimated Fix Time:** 13.5 hours

---

**Next Steps:**

1. Address P0 issues immediately (transactions, error handling)
2. Implement timeout configurations
3. Add rate limiting for external APIs
4. Add comprehensive type hints
5. Increase logging verbosity with context
