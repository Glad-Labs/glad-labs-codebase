# üèóÔ∏è Glad Labs: Task Pipeline & Real-Time Architecture Proposal

**Date:** November 3, 2025  
**Status:** ‚è≥ AWAITING YOUR APPROVAL  
**Decision Required By:** Before Implementation  
**Effort Estimate:** 4-6 weeks (development, testing, deployment)

---

## üéØ Executive Summary

This proposal outlines a **complete overhaul** of the content generation pipeline to:

1. **Preserve self-assessment core value** - Keep existing multi-step quality evaluation and scoring
2. **Implement real-time visibility** - Stream verbose logs to Oversight Hub as tasks progress
3. **Use MCP for agent orchestration** - Leverage Model Context Protocol for flexible tool calling
4. **Add Redis for task state management** - Track live progress, enable task cancellation, priority queues
5. **Optional queue system** - RabbitMQ for future scaling (deferred unless you want complexity now)

**Bottom Line:** Your system is 90% ready. The missing piece is connecting PostgreSQL tasks to the content generation pipeline with real-time status updates. This proposal fixes that while preserving your self-critique loops.

---

## ‚ùå Current Problems

### Problem 1: Disconnected Pipeline

```
Oversight Hub ‚Üí POST /api/tasks ‚Üí PostgreSQL ‚úÖ
    BUT
PostgreSQL Tasks ‚ùå ‚Üí Content Generation (independent system)
Content Generation ‚ùå ‚Üí Strapi Publishing
```

**Impact:** Tasks created from Oversight Hub are orphaned. They never generate content.

### Problem 2: No Real-Time Status

- Frontend polls `/api/tasks/{id}` every 2-5 seconds (inefficient)
- No streaming updates on what's happening (generate? validating? publishing?)
- User sees "pending" ‚Üí "completed" with no visibility into intermediate steps
- Backend logs are in 4 separate systems (FastAPI, Ollama, Strapi, database)

### Problem 3: Self-Assessment Logic Underutilized

- Excellent self-critique pipeline exists (`AIContentGenerator._validate_content()`)
- Quality scores (0-10) and issue tracking working perfectly
- But frontend doesn't show this verbose feedback during generation
- User doesn't see "Initial score: 6.2/10, issues: missing examples, needs stronger conclusion"

### Problem 4: Scaling Complexity

- No task prioritization system
- No task cancellation
- No retry logic for failed generations
- Direct function calls (not queue-based)

---

## ‚úÖ Your Existing Assets

### Self-Assessment System (CORE VALUE - PRESERVE)

```python
# src/cofounder_agent/services/ai_content_generator.py
class AIContentGenerator:
    def _validate_content(self):
        # Returns: quality_score (0-10), issues[], feedback
        # Checks: length, structure, headings, examples, CTA, tone, etc.

    async def generate_blog_post():
        # Generation loop with validation
        # Refinement attempts (up to 3)
        # Returns full metrics including validation_results
```

**Usage in generation:**

1. Generate draft ‚Üí Validate (score: 6.5/10)
2. Issues found ‚Üí Refinement loop
3. Validate again (score: 8.2/10) ‚Üí Accept
4. Track all attempts in metrics

**Current Metrics Tracked:**

- `validation_results`: List of each attempt with score, issues, passed
- `final_quality_score`: 0-10
- `generation_attempts`: How many tries?
- `refinement_attempts`: How many refinements?
- `model_used`: Which AI model?
- `generation_time_seconds`: Total time

### MCP Infrastructure (ALREADY BUILT)

```python
# src/mcp/mcp_orchestrator.py
# src/mcp/client_manager.py
# src/mcp/base_server.py

# Already implements:
‚úÖ Tool registration system
‚úÖ Server discovery
‚úÖ Tool calling with arguments
‚úÖ Resource management
‚úÖ Error handling
```

### Content Generation System (WORKING)

```python
# src/cofounder_agent/routes/content.py - POST /api/content/blog-posts
# Already does:
‚úÖ Generate content with self-checking
‚úÖ Search featured images
‚úÖ Publish to Strapi
‚úÖ Background task processing
‚úÖ Full metrics tracking
```

### PostgreSQL Schema (READY)

```sql
-- tasks table with all needed columns:
id, task_name, topic, primary_keyword, target_audience,
category, status, agent_id, user_id, metadata,
created_at, updated_at, started_at, completed_at,
task_metadata, result
```

---

## üéØ Proposed Solution Architecture

### Option A: MCP + Redis (RECOMMENDED)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         OVERSIGHT HUB (React)                   ‚îÇ
‚îÇ  - WebSocket connection to backend              ‚îÇ
‚îÇ  - Real-time progress stream                    ‚îÇ
‚îÇ  - Verbose logs: API, Ollama, FastAPI, Strapi  ‚îÇ
‚îÇ  - Quality scores & issues displayed live       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ WebSocket
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     FASTAPI ORCHESTRATOR (Main)                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Task Router (POST /api/tasks)             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Validate request                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Create PostgreSQL task record           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Add to Redis queue (priority)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Trigger background worker               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Return task_id immediately              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Task Status Endpoint (GET /api/tasks/{id})‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Fetch from PostgreSQL                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - Return: status, progress %, stage, logs ‚îÇ ‚îÇ
‚îÇ  ‚îÇ - WebSocket push on updates               ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   REDIS QUEUE    ‚îÇ  ‚îÇ   PostgreSQL DB  ‚îÇ
‚îÇ  (Task State)    ‚îÇ  ‚îÇ  (Persistence)   ‚îÇ
‚îÇ                  ‚îÇ  ‚îÇ                  ‚îÇ
‚îÇ - Priority Q     ‚îÇ  ‚îÇ - Tasks table    ‚îÇ
‚îÇ - Task metadata  ‚îÇ  ‚îÇ - Results        ‚îÇ
‚îÇ - Status updates ‚îÇ  ‚îÇ - Logs           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚ñ≤
        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  BACKGROUND WORKER (FastAPI Task)        ‚îÇ
‚îÇ                                          ‚îÇ
‚îÇ  for each task in redis_queue:           ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Stage 1: Generate Content         ‚îÇ
‚îÇ    ‚îÇ   - Call AIContentGenerator          ‚îÇ
‚îÇ    ‚îÇ   - Capture ALL validation results  ‚îÇ
‚îÇ    ‚îÇ   - Update Redis: progress 0% ‚Üí 25% ‚îÇ
‚îÇ    ‚îÇ   - Stream logs to WebSocket        ‚îÇ
‚îÇ    ‚îÇ                                     ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Stage 2: Search Images            ‚îÇ
‚îÇ    ‚îÇ   - Get featured image URL          ‚îÇ
‚îÇ    ‚îÇ   - Update Redis: progress 25% ‚Üí 50%‚îÇ
‚îÇ    ‚îÇ   - Stream logs to WebSocket        ‚îÇ
‚îÇ    ‚îÇ                                     ‚îÇ
‚îÇ    ‚îú‚îÄ‚Üí Stage 3: Publish to Strapi        ‚îÇ
‚îÇ    ‚îÇ   - Create post in CMS              ‚îÇ
‚îÇ    ‚îÇ   - Get Strapi post ID              ‚îÇ
‚îÇ    ‚îÇ   - Update Redis: progress 50% ‚Üí 75%‚îÇ
‚îÇ    ‚îÇ   - Stream logs to WebSocket        ‚îÇ
‚îÇ    ‚îÇ                                     ‚îÇ
‚îÇ    ‚îî‚îÄ‚Üí Stage 4: Finalize                 ‚îÇ
‚îÇ        - Update PostgreSQL with results  ‚îÇ
‚îÇ        - Clear Redis entry               ‚îÇ
‚îÇ        - Update Redis: progress 100%     ‚îÇ
‚îÇ        - Stream COMPLETE log             ‚îÇ
‚îÇ                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Redis Structure (Proposed)

```python
# Task Queue (Priority)
tasks:queue:high     # High priority tasks
tasks:queue:normal   # Standard priority (default)
tasks:queue:low      # Low priority

# Task Progress (Live Status)
tasks:progress:{task_id}
{
    "status": "in_progress",
    "stage": "generating_content",
    "progress_percent": 25,
    "current_step": "Initial draft generation - Ollama:mistral",
    "started_at": "2025-11-03T10:00:00Z"
}

# Task Logs (Real-Time Stream)
tasks:logs:{task_id}  # Redis stream with all logs
tasks:events:{task_id}  # Events (stage change, quality score, etc.)

# Task Result (Cached)
tasks:result:{task_id}
{
    "content": "...",
    "quality_score": 8.5,
    "model_used": "Ollama - mistral",
    "strapi_post_id": "123",
    "metadata": {...},
    "completed_at": "2025-11-03T10:02:30Z"
}
```

### MCP Enhancements (Proposed)

#### 1. Add MCP Tool: CreateTaskWithMCP

```python
# src/mcp/servers/task_server.py (NEW)

class TaskMCPServer(BaseMCPServer):
    """MCP server for task management"""

    @register_tool("create_task")
    async def create_task(self,
        topic: str,
        style: str,
        tone: str,
        target_length: int,
        tags: List[str]) -> Dict:
        """Create content generation task via MCP"""
        # ‚Üí Calls task_routes.create_task()
        # ‚Üí Returns task_id + queue position

    @register_tool("get_task_status")
    async def get_task_status(self, task_id: str) -> Dict:
        """Get live task status with progress"""
        # ‚Üí Fetches from Redis
        # ‚Üí Returns: progress %, stage, logs, quality score

    @register_tool("cancel_task")
    async def cancel_task(self, task_id: str) -> Dict:
        """Cancel running task"""
        # ‚Üí Removes from Redis queue
        # ‚Üí Updates PostgreSQL status = "cancelled"
```

#### 2. Add MCP Tool: StreamLogs

```python
class TaskMCPServer:
    @register_tool("get_task_logs")
    async def get_task_logs(self, task_id: str) -> Dict:
        """Get all logs for a task"""
        # Returns:
        # - FastAPI logs
        # - Ollama inference logs
        # - Validation feedback
        # - Strapi API logs
        # - Quality scores at each stage
```

---

## üìä Implementation Plan

### Phase 1: Redis Foundation (Week 1-2)

**Goal:** Task state management with persistence

**Tasks:**

1. Add redis-py to requirements.txt
2. Create `services/redis_service.py`
   - Connection pooling
   - Queue operations (push, pop, list)
   - Progress tracking (get, set, increment)
   - Log streaming (append, read)
3. Create `services/task_queue_manager.py`
   - Task priority handling
   - Queue monitoring
   - Metrics (queue size, processing speed)
4. Update `main.py` lifespan
   - Initialize Redis on startup
   - Health check endpoint
5. Create `/api/health/redis` endpoint

**Deliverable:** Redis running, can queue and retrieve tasks

**Estimated Effort:** 15-20 hours

---

### Phase 2: PostgreSQL ‚Üî Redis Bridge (Week 2-3)

**Goal:** Task creation triggers content generation

**Tasks:**

1. Update `task_routes.py`
   - After POST /api/tasks creates record
   - Push task to Redis queue
   - Return task_id + queue position
2. Create `background_worker.py`
   - Listen to Redis queue
   - For each task:
     - Update PostgreSQL status = "in_progress"
     - Update Redis progress = 0%
     - Call `AIContentGenerator.generate_blog_post()`
     - Capture every validation result
     - Push logs to Redis stream at each step
     - Update progress (25%, 50%, 75%, 100%)
     - Update PostgreSQL with final result

3. Create `task_processor.py`
   - Orchestrates entire pipeline
   - Error handling + retry logic
   - Strapi integration
   - Database updates

**Pseudo-code:**

```python
# background_worker.py
async def process_task_queue():
    while True:
        task_id = await redis.pop_from_queue()
        if not task_id:
            await asyncio.sleep(1)
            continue

        try:
            # Get task data from PostgreSQL
            task = await db.get_task(task_id)

            # STAGE 1: Generate
            await redis.set_progress(task_id, 0, "Generating content...")
            logger.info(f"[Stage 1] Starting content generation for {task_id}")

            generator = AIContentGenerator()
            content, model, metrics = await generator.generate_blog_post(
                topic=task.topic,
                style=task.metadata.get("style", "professional"),
                tone=task.metadata.get("tone", "professional"),
                target_length=task.metadata.get("length", 1000),
                tags=task.metadata.get("tags", [])
            )

            # Capture ALL validation results
            validation_details = {
                "attempts": metrics["validation_results"],
                "final_score": metrics["final_quality_score"],
                "model": model,
                "refinements": metrics["refinement_attempts"]
            }

            await redis.push_log(task_id, {
                "type": "generation_complete",
                "quality_score": validation_details["final_score"],
                "issues": validation_details["attempts"][-1].get("issues", [])
            })

            await redis.set_progress(task_id, 25, "Content generated ‚úì")

            # STAGE 2: Images
            await redis.set_progress(task_id, 25, "Searching for images...")
            logger.info(f"[Stage 2] Searching images for {task_id}")

            image_service = FeaturedImageService()
            image_url = await image_service.search_featured_image(task.topic)

            await redis.push_log(task_id, {
                "type": "image_found",
                "url": image_url
            })

            await redis.set_progress(task_id, 50, "Image found ‚úì")

            # STAGE 3: Strapi Publishing
            await redis.set_progress(task_id, 50, "Publishing to CMS...")
            logger.info(f"[Stage 3] Publishing to Strapi for {task_id}")

            strapi = StrapiPublishingService()
            result = await strapi.publish_blog_post(
                title=content_title,
                content=content,
                featured_image=image_url,
                tags=task.metadata.get("tags", [])
            )

            await redis.push_log(task_id, {
                "type": "published",
                "strapi_id": result["id"],
                "url": result["url"]
            })

            await redis.set_progress(task_id, 75, "Published to Strapi ‚úì")

            # STAGE 4: Finalize
            await redis.set_progress(task_id, 100, "Complete!")

            await db.update_task(task_id, {
                "status": "completed",
                "result": {
                    "content": content,
                    "quality_score": validation_details["final_score"],
                    "strapi_id": result["id"],
                    "validation": validation_details,
                    "completed_at": datetime.utcnow().isoformat()
                }
            })

            await redis.delete_progress(task_id)  # Clean up
            logger.info(f"‚úì Task {task_id} completed successfully")

        except Exception as e:
            logger.error(f"‚úó Task {task_id} failed: {e}")
            await db.update_task(task_id, {
                "status": "failed",
                "error": str(e)
            })
            await redis.push_log(task_id, {
                "type": "error",
                "error": str(e)
            })
```

**Deliverable:** Oversight Hub ‚Üí /api/tasks ‚Üí Redis Queue ‚Üí Background Worker ‚Üí Strapi

**Estimated Effort:** 20-25 hours

---

### Phase 3: WebSocket Real-Time Status (Week 3)

**Goal:** Frontend sees verbose updates as task runs

**Tasks:**

1. Create `services/websocket_manager.py`
   - Manages WebSocket connections per user
   - Broadcasts progress updates
   - Pushes log entries in real-time
   - Handles disconnection cleanup

2. Create `routes/ws_routes.py`
   - `GET /ws/tasks/{task_id}`
   - Authenticate user
   - Stream updates until task complete
   - Format: JSON line-delimited

3. Update Oversight Hub frontend
   - Connect WebSocket on task creation
   - Display progress bar (0-100%)
   - Display current stage with emoji
   - Verbose logs panel (scrollable)
   - Quality scores in real-time

**WebSocket Message Format:**

```json
// Progress update
{
  "type": "progress",
  "task_id": "abc-123",
  "percent": 25,
  "stage": "generating_content",
  "message": "Initial draft generated - score 6.5/10"
}

// Log entry
{
  "type": "log",
  "task_id": "abc-123",
  "level": "info",
  "source": "ollama",
  "message": "Model: mistral:latest, Prompt tokens: 245, Response tokens: 1,234"
}

// Quality update
{
  "type": "quality",
  "task_id": "abc-123",
  "score": 6.5,
  "issues": ["Missing examples", "Weak conclusion"],
  "feedback": "‚úó Content needs improvement (6.5/10, threshold: 7.0)"
}

// Complete
{
  "type": "complete",
  "task_id": "abc-123",
  "status": "success",
  "strapi_id": "post-456",
  "final_score": 8.2
}
```

**Frontend Component:**

```jsx
<TaskProgress taskId={taskId}>
  Progress: 25% Stage: Generating content (Ollama:mistral) Quality Score: 6.5/10
  Issues Found: - Missing practical examples - Weak call-to-action [Real-time
  logs...] [2025-11-03 10:00:15] Ollama: Model loaded [2025-11-03 10:00:20]
  FastAPI: Generation started [2025-11-03 10:01:15] Validator: Quality check
  complete (score: 6.5) [2025-11-03 10:01:16] Refinement: Attempting improvement
  ...
</TaskProgress>
```

**Deliverable:** Real-time visibility into task execution

**Estimated Effort:** 15-20 hours

---

### Phase 4: MCP Integration (Week 4)

**Goal:** Use MCP for agent orchestration + tool flexibility

**Tasks:**

1. Create `src/mcp/servers/task_server.py`
   - Implement TaskMCPServer class
   - Register tools: create_task, get_task_status, cancel_task
   - Integrate with Redis + PostgreSQL

2. Update `mcp_integration.py`
   - MCPEnhancedCoFounder can now:
     - Create tasks via MCP
     - Get task status
     - See progress in real-time
     - Cancel if needed

3. Test MCP tool integration
   - Verify tool calling
   - Verify data flow

**Deliverable:** MCP servers expose task management

**Estimated Effort:** 10-15 hours

---

### Phase 5: Polish & Testing (Week 5-6)

**Goal:** Production-ready system

**Tasks:**

1. Error handling + retry logic
   - Ollama timeouts?
   - Strapi connection failures?
   - Redis down?
   - Graceful degradation

2. Task cancellation
   - Remove from Redis queue
   - Update status in PostgreSQL
   - Stop background worker gracefully

3. Metrics & monitoring
   - Queue size endpoint
   - Processing speed (avg time per task)
   - Success/failure rates
   - Peak hours analysis

4. Testing
   - Unit tests for Redis operations
   - Integration tests (full pipeline)
   - Load tests (multiple concurrent tasks)
   - WebSocket connection tests

5. Documentation
   - Architecture diagrams
   - API endpoint docs
   - Troubleshooting guide
   - Deployment instructions

**Deliverable:** Production-ready system

**Estimated Effort:** 20-30 hours

---

## üöÄ Why Option A (MCP + Redis)?

| Aspect                        | Option A            | Option B          | Option C              |
| ----------------------------- | ------------------- | ----------------- | --------------------- |
| **Complexity**                | Medium              | Low               | High                  |
| **Scalability**               | ‚≠ê‚≠ê‚≠ê‚≠ê            | ‚≠ê‚≠ê              | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê            |
| **Real-time Visibility**      | ‚úÖ (WebSocket)      | ‚ùå (Polling only) | ‚úÖ (Both)             |
| **Task Prioritization**       | ‚úÖ                  | ‚ùå                | ‚úÖ                    |
| **Cost**                      | $0 (you have Redis) | $0                | $50-100/mo (RabbitMQ) |
| **Effort**                    | 4-6 weeks           | 1-2 weeks         | 8-10 weeks            |
| **Preserves Self-Assessment** | ‚úÖ                  | ‚úÖ                | ‚úÖ                    |
| **Cloud-Ready**               | ‚úÖ                  | ‚úÖ                | ‚úÖ                    |
| **Best For**                  | Your current setup  | Ultra-simple      | Enterprise scale      |

---

## ü§î Should You Add RabbitMQ Now?

### NO. Here's why:

1. **You already have Redis deployed** on Railway
2. **Single developer** - no need for distributed message broker complexity
3. **Current volume** - likely <100 tasks/day
4. **Redis does everything you need:**
   - Task queuing
   - Priority handling
   - State management
   - Streaming logs
   - Easy to monitor

### WHEN to add RabbitMQ:

- [ ] Multiple backend servers (horizontal scaling)
- [ ] Multiple teams working on different agents
- [ ] > 10,000 tasks/day
- [ ] Need guaranteed message delivery guarantees
- [ ] Routing between different worker types

**Recommendation:** Skip RabbitMQ now. If you hit scaling limits later (unlikely in year 1), migrate then.

---

## üìã What Stays the Same

### ‚úÖ Preserve Completely

1. **Self-assessment system** (`AIContentGenerator._validate_content()`)
   - All quality scoring remains
   - All issue tracking remains
   - All refinement loops remain
   - We just expose them to frontend

2. **Existing routes**
   - `/api/content/blog-posts` still works
   - `/api/models/*` still works
   - `/api/agents/*` still works
   - Add to, don't replace

3. **MCP infrastructure**
   - All existing servers remain
   - Add TaskMCPServer alongside them
   - No breaking changes

4. **Strapi integration**
   - No changes to publishing
   - Same CMS API calls
   - Same data structures

5. **PostgreSQL schema**
   - Tasks table already perfect
   - Just add new status values
   - Add new columns? Nope, metadata JSONB handles everything

---

## ‚ö†Ô∏è Breaking Changes

### NONE!

All changes are **additive**:

- New Redis service (alongside PostgreSQL)
- New background worker (new process, doesn't affect existing)
- New WebSocket endpoint (new, doesn't affect REST)
- New task routes (new, don't touch existing content routes)

**Backward compatibility:** 100%

---

## üìä Success Metrics

After implementation, you'll have:

‚úÖ **Oversight Hub Workflow Works End-to-End**

```
1. Click "Generate Blog Post"
2. See real-time progress (25%, 50%, 75%, 100%)
3. Watch quality scores tick up (6.2 ‚Üí 7.1 ‚Üí 8.5)
4. See all logs: Ollama inference, validation checks, Strapi API calls
5. Post auto-publishes to Strapi when complete
6. Task card shows "‚úì Published" with link to post
```

‚úÖ **Full Visibility into AI Processing**

```
Real-time logs show:
- Ollama model loading
- Token counts (prompt + response)
- Quality validation at each step
- Refinement attempts with feedback
- Image search results
- Strapi API calls
- All timestamps
```

‚úÖ **Measurable Quality Improvements**

```
- Track quality scores per attempt
- See which refinements helped
- Identify patterns (what topics need more refinement?)
- Benchmark: average time per task, success rate
```

‚úÖ **Operational Control**

```
- Cancel running tasks
- Prioritize urgent content
- Retry failed tasks
- View queue depth in real-time
```

---

## üõ†Ô∏è Technical Notes

### Database Transactions

- Keep PostgreSQL as source of truth
- Redis is cache layer only
- If Redis crashes, data recovers from PostgreSQL
- Task recovery: Check status in DB, resume from where it left off

### Error Scenarios

```
Ollama times out?
  ‚Üí Fallback to HuggingFace/Gemini
  ‚Üí Log the failure
  ‚Üí Continue to stage 2

Strapi API fails?
  ‚Üí Retry 3 times with exponential backoff
  ‚Üí If all fail: mark task "failed"
  ‚Üí User can retry from Oversight Hub

Redis connection lost?
  ‚Üí Use in-memory fallback queue
  ‚Üí When Redis recovers, flush memory to persistent storage
```

### Load Handling

```
Tasks arrive faster than they complete?
  ‚Üí Queue fills up (normal, by design)
  ‚Üí Show "X tasks in queue, estimated wait: 5 min"
  ‚Üí Allow user to set priority
  ‚Üí Process high-priority first

All workers fail?
  ‚Üí Supervisor process restarts them
  ‚Üí Alert team
  ‚Üí Oldest tasks resume first
```

---

## üí∞ Cost Analysis

### Current Monthly (estimated)

- Railway PostgreSQL: $15
- Railway FastAPI: $25
- Vercel Frontend: $20
- **Total: $60/month**

### After Implementation

- Railway PostgreSQL: $15 (no change)
- Railway FastAPI: $25 (maybe $30 with more processing)
- Railway Redis: $10 (you already have it)
- Vercel Frontend: $20 (no change)
- **Total: $65-70/month** ‚úÖ

### RabbitMQ Comparison

- Would add: $50-100/month
- Not recommended unless you scale

---

## üé¨ Next Steps (If Approved)

1. **You approve this plan** ‚úì
2. I create GitHub issue with detailed tasks
3. Break Phase 1 into 5-6 day sprints
4. Start with Redis service
5. Incrementally add each layer
6. Test at each phase
7. Deploy to production when complete

---

## ‚ùì Questions for You

Before I proceed, please clarify:

1. **Verbose Logging Preferences**
   - How much detail? (timestamp for every step?)
   - Should logs persist in PostgreSQL for audit trail?
   - Archive old logs automatically?

2. **Task Prioritization**
   - Simple (high/normal/low) or complex (numeric score)?
   - Can users change priority after task starts?

3. **Error Recovery**
   - How many retries before giving up?
   - Should failed tasks auto-retry or wait for user action?

4. **UI Preferences**
   - Live logs panel scrollable?
   - Auto-scroll to bottom or stay where user scrolled?
   - Show raw API requests or human-readable summaries?

5. **Real-time vs Batch**
   - Must progress updates be instant (WebSocket)?
   - Or polling every 2-5 seconds acceptable?

6. **Monitoring/Alerting**
   - Should you get Slack alerts if task fails?
   - Monitor queue depth on Oversight Hub?

7. **Timeline Flexibility**
   - Can you wait 4-6 weeks for production?
   - Or need MVP sooner (skip some polish)?

---

## üìù Decision Template

**Please approve/revise this plan:**

```
Architecture: [MCP + Redis ‚úÖ / Modify Phase X / Use Option C instead]

Redis Deployment: [Yes, I have it on Railway ‚úÖ / Need to set up first]

Real-time Priority: [WebSocket NOW / Polling OK for now / Defer to later]

Task Prioritization: [Simple (high/normal/low) / Complex / Defer]

Testing Rigor: [Comprehensive / Balanced / MVP-ready]

Timeline: [4-6 weeks is fine / Need faster / Can wait longer]

Additional Questions/Constraints: [...]
```

---

## üìö References

- Current self-assessment code: `src/cofounder_agent/services/ai_content_generator.py`
- MCP infrastructure: `src/mcp/mcp_orchestrator.py`
- Existing PostgreSQL schema: `.env` + `src/cofounder_agent/routes/task_routes.py`
- Redis already deployed on Railway (verified in your staging setup)

---

**Status:** ‚è≥ AWAITING YOUR APPROVAL

Once approved, I'll create detailed sprint plans and start implementation.
