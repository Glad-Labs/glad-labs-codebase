# Robots.txt for Glad Labs Blog
# This file tells search engines which pages to crawl and index

# Allow all crawlers to index everything by default
User-agent: *
Allow: /
Disallow: /_next/
Disallow: /api/
Disallow: /.well-known/

# Point to sitemap - UPDATE THIS TO YOUR ACTUAL DOMAIN
Sitemap: https://yourdomain.com/sitemap.xml

# Crawl delay (optional - prevents server overload)
# Crawl-delay: 1

# Specific rules for Google
User-agent: Googlebot
Allow: /

# Specific rules for Bing
User-agent: Bingbot
Allow: /

# Block bad bots
User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot
Disallow: /

User-agent: DotBot
Disallow: /
