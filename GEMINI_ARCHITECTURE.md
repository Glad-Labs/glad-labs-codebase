# Gemini Testing Architecture & Flow

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Oversight Hub (React)                        â”‚
â”‚                    http://localhost:3001                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Model Selector Dropdown                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚   â”‚
â”‚  â”‚  â”‚ â˜ï¸ gemini-1.5-pro                    â”‚ â† SELECT HERE  â”‚   â”‚
â”‚  â”‚  â”‚ â˜ï¸ gemini-1.5-flash                  â”‚                â”‚   â”‚
â”‚  â”‚  â”‚ ğŸ–¥ï¸ mistral:latest (ollama)           â”‚                â”‚   â”‚
â”‚  â”‚  â”‚ ğŸ§  claude-3-opus (anthropic)         â”‚                â”‚   â”‚
â”‚  â”‚  â”‚ âš¡ gpt-4-turbo (openai)              â”‚                â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚   â”‚
â”‚  â”‚                    â†“                                       â”‚   â”‚
â”‚  â”‚  Chat Input: "What is your model name?"                  â”‚   â”‚
â”‚  â”‚                    â†“                                       â”‚   â”‚
â”‚  â”‚  [SEND] Button                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ POST /api/chat
                      â”‚ model: "gemini-1.5-pro"
                      â”‚ message: "What is your model name?"
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  FastAPI Backend (Python)                        â”‚
â”‚                 http://localhost:8000                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Chat Route Handler                                      â”‚   â”‚
â”‚  â”‚  POST /api/chat                                          â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  1. Parse request (model, message, conversationId)       â”‚   â”‚
â”‚  â”‚                    â†“                                      â”‚   â”‚
â”‚  â”‚  2. Model Router: route_request()                        â”‚   â”‚
â”‚  â”‚     Check: provider = "google"                           â”‚   â”‚
â”‚  â”‚                    â†“                                      â”‚   â”‚
â”‚  â”‚  3. Initialize: GoogleGenerativeAI(api_key)              â”‚   â”‚
â”‚  â”‚                    â†“                                      â”‚   â”‚
â”‚  â”‚  4. Send to Gemini API:                                  â”‚   â”‚
â”‚  â”‚     model.generate_content(message)                      â”‚   â”‚
â”‚  â”‚                    â†“                                      â”‚   â”‚
â”‚  â”‚  5. Parse response                                       â”‚   â”‚
â”‚  â”‚     Extract: response_text, tokens_used, timestamp       â”‚   â”‚
â”‚  â”‚                    â†“                                      â”‚   â”‚
â”‚  â”‚  6. Store in PostgreSQL:                                 â”‚   â”‚
â”‚  â”‚     - Conversation history                               â”‚   â”‚
â”‚  â”‚     - Model metadata                                     â”‚   â”‚
â”‚  â”‚     - Tokens used                                        â”‚   â”‚
â”‚  â”‚                    â†“                                      â”‚   â”‚
â”‚  â”‚  7. Return ChatResponse(...)                             â”‚   â”‚
â”‚  â”‚     provider: "google"                                   â”‚   â”‚
â”‚  â”‚     model: "gemini-1.5-pro"                              â”‚   â”‚
â”‚  â”‚     response: "I'm Gemini..."                            â”‚   â”‚
â”‚  â”‚     tokens_used: 42                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ HTTPS to Google API
                      â”‚ https://generativelanguage.googleapis.com
                      â”‚
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Google Gemini API                             â”‚
â”‚              (Cloud Endpoints)                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Models Available:                                       â”‚   â”‚
â”‚  â”‚  â€¢ gemini-1.5-pro (recommended)                         â”‚   â”‚
â”‚  â”‚  â€¢ gemini-1.5-flash (faster)                            â”‚   â”‚
â”‚  â”‚  â€¢ gemini-pro (legacy)                                  â”‚   â”‚
â”‚  â”‚  â€¢ gemini-pro-vision (multimodal)                       â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  Request:                                                â”‚   â”‚
â”‚  â”‚  {                                                        â”‚   â”‚
â”‚  â”‚    "contents": [{                                         â”‚   â”‚
â”‚  â”‚      "parts": [{"text": "What is your model name?"}]     â”‚   â”‚
â”‚  â”‚    }]                                                     â”‚   â”‚
â”‚  â”‚  }                                                        â”‚   â”‚
â”‚  â”‚                                                           â”‚   â”‚
â”‚  â”‚  Response:                                               â”‚   â”‚
â”‚  â”‚  {                                                        â”‚   â”‚
â”‚  â”‚    "candidates": [{                                       â”‚   â”‚
â”‚  â”‚      "content": {                                         â”‚   â”‚
â”‚  â”‚        "parts": [{"text": "I'm Gemini..."}]              â”‚   â”‚
â”‚  â”‚      },                                                   â”‚   â”‚
â”‚  â”‚      "finishReason": "STOP"                              â”‚   â”‚
â”‚  â”‚    }],                                                    â”‚   â”‚
â”‚  â”‚    "usageMetadata": {                                     â”‚   â”‚
â”‚  â”‚      "promptTokens": 10,                                 â”‚   â”‚
â”‚  â”‚      "candidatesTokens": 32                              â”‚   â”‚
â”‚  â”‚    }                                                      â”‚   â”‚
â”‚  â”‚  }                                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Request Flow Sequence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Oversight Hub  â”‚
â”‚  (UI)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ 1. User selects "gemini-1.5-pro"
         â”‚ 2. User types message
         â”‚ 3. User clicks [SEND]
         â”‚
         â†“
    JSON Request
    POST /api/chat
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    {
      "conversationId": "unique-id-123",
      "model": "gemini-1.5-pro",
      "message": "What is your model name?"
    }
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FastAPI Backend Routes               â”‚
â”‚    /routes/chat_routes.py                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”‚ Route: POST /api/chat
           â”‚ Handler: send_message()
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. VALIDATE REQUEST                    â”‚
â”‚  - Check model name valid               â”‚
â”‚  - Check conversationId provided        â”‚
â”‚  - Check message not empty              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. SELECT PROVIDER                     â”‚
â”‚  ModelRouter.route_request()            â”‚
â”‚  - Provider detection: google           â”‚
â”‚  - Complexity analysis: auto            â”‚
â”‚  - Load model settings                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. INITIALIZE CLIENT                   â”‚
â”‚  google.generativeai.GenerativeModel()  â”‚
â”‚  - Load API key: GOOGLE_API_KEY         â”‚
â”‚  - Set model: gemini-1.5-pro            â”‚
â”‚  - Configure safety settings            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PREPARE MESSAGE                     â”‚
â”‚  - Build full prompt                    â”‚
â”‚  - Load conversation history            â”‚
â”‚  - Add system context                   â”‚
â”‚  - Set max_tokens (if applicable)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
    HTTPS Request
    POST https://generativelanguage.googleapis.com
    /v1beta/models/gemini-1.5-pro:generateContent
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Headers:
      x-goog-api-key: AIzaSy...
      Content-Type: application/json

    Body:
      {
        "contents": [{
          "parts": [{"text": "What is your model name?"}]
        }],
        "generationConfig": {
          "maxOutputTokens": 1000,
          "temperature": 0.7
        },
        "safetySettings": [...]
      }
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOOGLE GEMINI SERVER                   â”‚
â”‚  - Process request                      â”‚
â”‚  - Generate response tokens             â”‚
â”‚  - Apply safety filters                 â”‚
â”‚  - Calculate token usage                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
    HTTPS Response
    200 OK
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    {
      "candidates": [{
        "content": {
          "parts": [{"text": "I'm Gemini..."}]
        },
        "finishReason": "STOP"
      }],
      "usageMetadata": {
        "promptTokens": 10,
        "candidatesTokens": 32,
        "totalTokens": 42
      }
    }
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. PARSE RESPONSE                      â”‚
â”‚  - Extract response text                â”‚
â”‚  - Extract token count: 42              â”‚
â”‚  - Extract finish reason: STOP          â”‚
â”‚  - Generate timestamp                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. STORE IN DATABASE                   â”‚
â”‚  PostgreSQL                             â”‚
â”‚  - INSERT into chat_history table       â”‚
â”‚  - conversationId: unique-id-123        â”‚
â”‚  - model_used: gemini-1.5-pro           â”‚
â”‚  - provider: google                     â”‚
â”‚  - message: "What is your model..."     â”‚
â”‚  - response: "I'm Gemini..."            â”‚
â”‚  - tokens_used: 42                      â”‚
â”‚  - timestamp: 2026-01-16T...            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â†“
    JSON Response
    200 OK
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ChatResponse {
      "response": "I'm Gemini...",
      "model": "gemini-1.5-pro",
      "provider": "google",
      "conversationId": "unique-id-123",
      "timestamp": "2026-01-16T12:34:56Z",
      "tokens_used": 42
    }
           â”‚
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Oversight Hub  â”‚
â”‚  (UI)           â”‚
â”‚  - Display      â”‚
â”‚    response     â”‚
â”‚  - Show metadataâ”‚
â”‚  - Update UI    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Model Selection Fallback Chain

```
User selects "gemini-1.5-pro"
          â”‚
          â†“
    Is Gemini available?
          â”‚
      YES â”‚ NO
          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â†“                                     â†“
    Use Gemini                           Try next provider
    "provider": "google"                 in fallback chain
                                                â”‚
                                                â†“
                                         Is HuggingFace available?
                                                â”‚
                                            YES â”‚ NO
                                                â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â†“               â†“
                                         Use HuggingFace   Try Claude
                                         "provider":       (Anthropic)
                                         "huggingface"     "provider":
                                                           "anthropic"
                                                                â”‚
                                                            YES â”‚ NO
                                                                â”‚  â””â”€â”€â”€â”€â”€â”
                                                                â†“        â†“
                                                           Use Claude Try GPT-4
                                                                       (OpenAI)
                                                                       "provider":
                                                                       "openai"


FALLBACK CHAIN (Priority Order):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. ğŸ–¥ï¸  Ollama        (Local, instant, FREE)
2. ğŸŒ HuggingFace   (Cheap, but slower)
3. â˜ï¸  Gemini        (Good balance: cost/quality)
4. ğŸ§  Claude        (Premium: excellent)
5. âš¡ GPT-4         (Expensive: best)


What Triggers Fallback:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ— API key not configured
âœ— API key invalid/expired
âœ— Rate limit exceeded (429)
âœ— API temporarily down (503)
âœ— Network error
âœ— Timeout (30+ seconds)
```

---

## Testing Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    START: Test Gemini                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEST 1: Environment Check       â”‚
        â”‚  curl $GOOGLE_API_KEY            â”‚
        â”‚  echo ${GOOGLE_API_KEY:0:10}     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        PASS? â”‚ â”‚ FAIL?
              â”‚ â””â”€â”€â”€â”€â”€â†’ âœ— Error: API key not set
              â”‚                  Solution: Add to .env.local
              â”‚
              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEST 2: Backend Running         â”‚
        â”‚  curl http://localhost:8000      â”‚
        â”‚  /api/health                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        PASS? â”‚ â”‚ FAIL?
              â”‚ â””â”€â”€â”€â”€â”€â†’ âœ— Error: Backend down
              â”‚                  Solution: npm run dev:cofounder
              â”‚
              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEST 3: Models Available        â”‚
        â”‚  curl /api/v1/models/available   â”‚
        â”‚  | jq '.models | length'         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        PASS? â”‚ â”‚ FAIL?
              â”‚ â””â”€â”€â”€â”€â”€â†’ âœ— Error: No models
              â”‚                  Solution: Check backend logs
              â”‚
              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEST 4: Gemini in List          â”‚
        â”‚  curl /api/v1/models/available   â”‚
        â”‚  | jq '.models[] | select       â”‚
        â”‚   (.provider=="google")'         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        PASS? â”‚ â”‚ FAIL?
              â”‚ â””â”€â”€â”€â”€â”€â†’ âœ— Error: No Gemini models
              â”‚                  Solution: API key invalid
              â”‚
              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEST 5: Send Chat Message       â”‚
        â”‚  curl -X POST /api/chat          â”‚
        â”‚  -d '{"model":"gemini-1.5...'   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        PASS? â”‚ â”‚ FAIL?
              â”‚ â””â”€â”€â”€â”€â”€â†’ âœ— Error: Check jq '.provider'
              â”‚                  (Should be "google")
              â”‚
              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TEST 6: UI Test                 â”‚
        â”‚  1. Open http://localhost:3001   â”‚
        â”‚  2. Select gemini-1.5-pro        â”‚
        â”‚  3. Send message                 â”‚
        â”‚  4. Verify response              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
        PASS? â”‚ â”‚ FAIL?
              â”‚ â””â”€â”€â”€â”€â”€â†’ âœ— Error: Check browser console
              â”‚                  (F12 â†’ Console tab)
              â”‚
              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  âœ“ ALL TESTS PASSED                     â”‚
    â”‚                                          â”‚
    â”‚  Gemini is working!                     â”‚
    â”‚                                          â”‚
    â”‚  You can now:                            â”‚
    â”‚  - Use Gemini in Oversight Hub          â”‚
    â”‚  - Send messages                         â”‚
    â”‚  - View conversation history             â”‚
    â”‚  - Monitor response metadata             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## API Endpoint Hierarchy

```
Backend: http://localhost:8000
â”‚
â”œâ”€â”€ /api/health
â”‚   â””â”€â”€ Status of entire system
â”‚
â”œâ”€â”€ /api/v1/models/
â”‚   â”œâ”€â”€ /available
â”‚   â”‚   â”œâ”€â”€ List all models (Ollama, HuggingFace, Gemini, Claude, GPT)
â”‚   â”‚   â””â”€â”€ Example: gemini-1.5-pro (â˜ï¸ provider: google)
â”‚   â”‚
â”‚   â”œâ”€â”€ /status
â”‚   â”‚   â”œâ”€â”€ Provider availability check
â”‚   â”‚   â””â”€â”€ Example: google: {available: true, models: 4}
â”‚   â”‚
â”‚   â””â”€â”€ /recommended
â”‚       â”œâ”€â”€ Best models by cost/tier
â”‚       â””â”€â”€ Example: [gemini-1.5-pro, claude-opus, gpt-4]
â”‚
â”œâ”€â”€ /api/chat
â”‚   â”œâ”€â”€ POST (send message)
â”‚   â”‚   â”œâ”€â”€ Input: model, conversationId, message
â”‚   â”‚   â””â”€â”€ Output: response, provider, tokens_used
â”‚   â”‚
â”‚   â”œâ”€â”€ GET /history/{id} (view conversation)
â”‚   â”‚   â””â”€â”€ Output: messages array with history
â”‚   â”‚
â”‚   â””â”€â”€ DELETE /history/{id} (clear conversation)
â”‚       â””â”€â”€ Output: success confirmation
â”‚
â””â”€â”€ /api/docs
    â””â”€â”€ Swagger UI (interactive API documentation)
```

---

## Storage & Persistence

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PostgreSQL Database                      â”‚
â”‚         glad_labs_dev (development)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€ TABLE: chat_history
            â”‚  â”œâ”€ conversation_id (UUID)
            â”‚  â”œâ”€ user_message (text)
            â”‚  â”œâ”€ assistant_response (text)
            â”‚  â”œâ”€ model_used (varchar)
            â”‚  â”‚  â””â”€ Example: "gemini-1.5-pro"
            â”‚  â”œâ”€ provider (varchar)
            â”‚  â”‚  â””â”€ Example: "google"
            â”‚  â”œâ”€ tokens_used (int)
            â”‚  â”‚  â””â”€ Example: 42
            â”‚  â”œâ”€ cost_estimate (float)
            â”‚  â”‚  â””â”€ Calculated based on provider/model
            â”‚  â”œâ”€ timestamp (datetime)
            â”‚  â””â”€ metadata (json)
            â”‚     â””â”€ {finish_reason, safety_ratings, etc}
            â”‚
            â”œâ”€ TABLE: tasks
            â”‚  â”œâ”€ task_id (UUID)
            â”‚  â”œâ”€ model_used (varchar)
            â”‚  â”œâ”€ status (enum)
            â”‚  â””â”€ result (json)
            â”‚
            â””â”€ TABLE: conversations
               â”œâ”€ conversation_id (UUID)
               â”œâ”€ title (varchar)
               â”œâ”€ created_at (datetime)
               â”œâ”€ updated_at (datetime)
               â””â”€ messages_count (int)
```

---

## Monitoring & Debugging Signals

```
HEALTHY STATE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Backend logs show: "[Chat] Using provider: google"
âœ“ Response includes: "provider": "google"
âœ“ Response time: 1-3 seconds
âœ“ UI shows Gemini in dropdown with â˜ï¸ icon
âœ“ No CORS errors in browser console
âœ“ Database stores conversation history


WARNING STATE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âš ï¸ Response time: 5-10 seconds (slow network or API lag)
âš ï¸ Some fallback happening (not using primary model)
âš ï¸ Rate limit warnings in logs
âš ï¸ Some API keys not configured (using reduced model set)


ERROR STATE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ— Response shows wrong provider (not "google")
âœ— "provider": "anthropic" or "openai" (fallback engaged)
âœ— Error in chat response (timeout, 429, 503)
âœ— Model not in dropdown
âœ— CORS errors in browser console
âœ— Backend logs: "[ERROR] Gemini API failed"


DEBUG SIGNALS:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ” Check: Backend logs for provider selection
ğŸ” Check: Browser DevTools â†’ Network tab â†’ /api/chat response
ğŸ” Check: Database with: SELECT * FROM chat_history WHERE provider='google'
ğŸ” Check: API key validity at https://aistudio.google.com/app/apikey
```

---

## Performance Expectations

```
Model: gemini-1.5-pro
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Response Time by Task:
  Simple greeting:        1-2 seconds
  3-sentence summary:     2-3 seconds
  Code generation:        3-4 seconds
  Analysis task:          3-5 seconds
  Complex reasoning:      4-6 seconds
  Network latency only:   + 1-2 seconds

Token Usage by Task:
  Simple greeting:        20-50 tokens
  3-sentence summary:     100-150 tokens
  Code generation:        200-500 tokens
  Full page analysis:     500-1000+ tokens

Cost (Gemini 1.5 Pro):
  Input:  $0.075 per 1M tokens  (~$0.00000075 per token)
  Output: $0.30 per 1M tokens   (~$0.0000030 per token)

Example Cost Calculation:
  Message 1: 10 input tokens + 32 output tokens
  Cost = (10 Ã— $0.00000075) + (32 Ã— $0.0000030)
  Cost â‰ˆ $0.000105 (0.0001 cents)

Monthly Estimate (100 messages/day):
  â‰ˆ $0.31/month


Comparison to Other Models:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Ollama (local):    FREE    âœ“ (instant, no internet)
HuggingFace:       FREE    âœ“ (free tier, rate limited)
Gemini 1.5 Pro:    $0.31   âœ“ (monthly estimate)
Claude 3 Opus:     $3.00   (monthly estimate)
GPT-4 Turbo:       $5.00   (monthly estimate)
```

---

**Status:** âœ… Ready for Testing  
**Last Updated:** January 16, 2026  
**Backend:** http://localhost:8000  
**Frontend:** http://localhost:3001
